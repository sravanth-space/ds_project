{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tVkNhAi-PeUo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.signal import find_peaks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from scipy.fft import rfft\n",
        "from statsmodels.tsa.stattools import acf\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KtXtdBe4PeUo"
      },
      "outputs": [],
      "source": [
        "# --- 1. Simulation Function ---\n",
        "def simulate_black_hole_lightcurve(fs, fc, fm, qpo_amplitude, duration,\n",
        "                                   noise_mean=0, noise_std=0.5,\n",
        "                                   include_qpo=True, modulation_index=0.5):\n",
        "    \"\"\"\n",
        "    Simulate a black hole light curve with stochastic noise and an amplitude-modulated QPO signal.\n",
        "\n",
        "    Parameters:\n",
        "        fs : int\n",
        "            Sampling frequency (Hz)\n",
        "        fc : float\n",
        "            Carrier frequency (Hz) for QPO\n",
        "        fm : float\n",
        "            Modulating frequency (Hz) for QPO\n",
        "        qpo_amplitude : float\n",
        "            Amplitude of the carrier signal (QPO)\n",
        "        duration : float\n",
        "            Duration of lightcurve (seconds)\n",
        "        noise_mean : float\n",
        "            Mean of the Gaussian noise\n",
        "        noise_std : float\n",
        "            Standard deviation of the Gaussian noise\n",
        "        include_qpo : bool\n",
        "            Whether to include the QPO signal\n",
        "        modulation_index : float\n",
        "            Modulation index for AM signal\n",
        "\n",
        "    Returns:\n",
        "        t : np.ndarray\n",
        "            Time array\n",
        "        flux : np.ndarray\n",
        "            Normalized flux array\n",
        "    \"\"\"\n",
        "    # Time array\n",
        "    t = np.arange(0, duration, 1/fs)\n",
        "\n",
        "    # White noise\n",
        "    white_noise = np.random.normal(noise_mean, noise_std, size=len(t))\n",
        "    white_noise = np.exp(white_noise)\n",
        "\n",
        "    if include_qpo and qpo_amplitude > 0:\n",
        "        # Modulating signal\n",
        "        msg = qpo_amplitude * np.cos(2 * np.pi * fm * t)\n",
        "\n",
        "        # Carrier signal\n",
        "        carrier = qpo_amplitude * np.cos(2 * np.pi * fc * t)\n",
        "\n",
        "        # AM QPO signal\n",
        "        qpo = carrier * (1 + modulation_index * msg / qpo_amplitude)\n",
        "    else:\n",
        "        qpo = 0\n",
        "\n",
        "    # Combine noise and QPO signal\n",
        "    flux = white_noise + qpo\n",
        "\n",
        "    # Normalize\n",
        "    flux = (flux - np.mean(flux)) / np.std(flux)\n",
        "\n",
        "    return t, flux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UX5X2jbRPeUp"
      },
      "outputs": [],
      "source": [
        "def generate_dataset_with_random_amplitudes(output_dir, num_samples=5000,\n",
        "                                            fs=1, duration=512,\n",
        "                                            modulation_index=0.5,\n",
        "                                            amp_range=(0.1, 1.0)):\n",
        "    \"\"\"\n",
        "    Generate dataset of light curves with random QPO amplitudes from a given range.\n",
        "\n",
        "    Parameters:\n",
        "        output_dir : str\n",
        "            Path to save dataset\n",
        "        num_samples : int\n",
        "            Total number of samples (half QPO, half non-QPO)\n",
        "        fs : int\n",
        "            Sampling frequency\n",
        "        duration : int\n",
        "            Length of each light curve in seconds\n",
        "        modulation_index : float\n",
        "            Modulation index for AM QPO\n",
        "        amp_range : tuple\n",
        "            Range of amplitudes for QPO (min, max)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    seq_length = int(duration * fs)\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    for _ in range(num_samples // 2):\n",
        "        # Random QPO parameters\n",
        "        fc = np.random.uniform(0.01, 1.0)\n",
        "        fm = np.random.uniform(0.005, 0.1)\n",
        "        amp = np.random.uniform(*amp_range)\n",
        "\n",
        "        # QPO light curve\n",
        "        t, flux_qpo = simulate_black_hole_lightcurve(\n",
        "            fs, fc, fm, amp, duration, include_qpo=True,\n",
        "            modulation_index=modulation_index)\n",
        "\n",
        "        # Non-QPO light curve (same params but QPO off)\n",
        "        _, flux_non_qpo = simulate_black_hole_lightcurve(\n",
        "            fs, fc, fm, amp, duration, include_qpo=False,\n",
        "            modulation_index=modulation_index)\n",
        "\n",
        "        dataset.append(flux_qpo[:seq_length].reshape(-1, 1))\n",
        "        labels.append(1)\n",
        "\n",
        "        dataset.append(flux_non_qpo[:seq_length].reshape(-1, 1))\n",
        "        labels.append(0)\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = to_categorical(np.array(labels), 2)\n",
        "\n",
        "    np.savez_compressed(os.path.join(output_dir, 'data.npz'), X=dataset, y=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zy_QxyjqPeUp"
      },
      "outputs": [],
      "source": [
        "output_folder = \"qpo_experiments/dataset_random_amp\"\n",
        "generate_dataset_with_random_amplitudes(\n",
        "    output_folder, num_samples=10000, amp_range=(0.6, 1.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uHL7FoccPeUp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_split_dataset(npz_path, batch_size=64, test_size=0.2, shuffle=True):\n",
        "    data = np.load(npz_path)\n",
        "    X = data['X']  # (N, 512, 1)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_val = train_test_split(X, test_size=test_size, random_state=42)\n",
        "\n",
        "    # TF Datasets\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(X_train.astype(np.float32))\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices(X_val.astype(np.float32))\n",
        "\n",
        "    if shuffle:\n",
        "        train_ds = train_ds.shuffle(buffer_size=10000)\n",
        "    train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n",
        "def load_conditional_dataset(npz_path, batch_size=64, test_size=0.2):\n",
        "    data = np.load(npz_path)\n",
        "    X = data['X'].astype(np.float32)\n",
        "    y = data['y'].astype(np.float32)  # Shape (N, 2)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(batch_size)\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_OdB7HtpPeUp"
      },
      "outputs": [],
      "source": [
        "def build_conditional_generator(latent_dim=100, label_dim=2, seq_length=512):\n",
        "    noise_input = tf.keras.Input(shape=(latent_dim,))\n",
        "    label_input = tf.keras.Input(shape=(label_dim,))\n",
        "\n",
        "    x = tf.keras.layers.Concatenate()([noise_input, label_input])\n",
        "    x = tf.keras.layers.Dense(128)(x)\n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "    x = tf.keras.layers.Dense(seq_length * 32)(x)\n",
        "    x = tf.keras.layers.Reshape((seq_length, 32))(x)\n",
        "    x = tf.keras.layers.GaussianNoise(0.05)(x)\n",
        "    x = tf.keras.layers.GRU(64, return_sequences=True)(x)\n",
        "    output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(x)\n",
        "\n",
        "    return tf.keras.Model([noise_input, label_input], output)\n",
        "\n",
        "\n",
        "def build_conditional_discriminator(seq_length=512, label_dim=2):\n",
        "    series_input = tf.keras.Input(shape=(seq_length, 1))\n",
        "    label_input = tf.keras.Input(shape=(label_dim,))\n",
        "\n",
        "    # Expand label to (seq_length, label_dim)\n",
        "    label_expanded = tf.keras.layers.RepeatVector(seq_length)(label_input)\n",
        "    x = tf.keras.layers.Concatenate()([series_input, label_expanded])\n",
        "\n",
        "    x = tf.keras.layers.GRU(64, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.GRU(32)(x)\n",
        "    x = tf.keras.layers.Dense(64)(x)\n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return tf.keras.Model([series_input, label_input], output)\n",
        "\n",
        "\n",
        "class ConditionalTimeSeriesGAN(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "        self.gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        self.disc_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    def compile(self):\n",
        "        super().compile()\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        real_series, labels = data\n",
        "        batch_size = tf.shape(real_series)[0]\n",
        "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
        "\n",
        "        # Train Discriminator\n",
        "        with tf.GradientTape() as disc_tape:\n",
        "            fake_series = self.generator([noise, labels], training=True)\n",
        "            real_output = self.discriminator(\n",
        "                [real_series, labels], training=True)\n",
        "            fake_output = self.discriminator(\n",
        "                [fake_series, labels], training=True)\n",
        "\n",
        "            real_labels = tf.ones((batch_size, 1))\n",
        "            fake_labels = tf.zeros((batch_size, 1))\n",
        "            disc_loss = self.loss_fn(\n",
        "                real_labels, real_output) + self.loss_fn(fake_labels, fake_output)\n",
        "\n",
        "        grads_disc = disc_tape.gradient(\n",
        "            disc_loss, self.discriminator.trainable_variables)\n",
        "        self.disc_optimizer.apply_gradients(\n",
        "            zip(grads_disc, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Train Generator\n",
        "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "            generated_series = self.generator([noise, labels], training=True)\n",
        "            fake_output = self.discriminator(\n",
        "                [generated_series, labels], training=True)\n",
        "            gen_loss = self.loss_fn(tf.ones((batch_size, 1)), fake_output)\n",
        "\n",
        "        grads_gen = gen_tape.gradient(\n",
        "            gen_loss, self.generator.trainable_variables)\n",
        "        self.gen_optimizer.apply_gradients(\n",
        "            zip(grads_gen, self.generator.trainable_variables))\n",
        "\n",
        "        return {\"gen_loss\": gen_loss, \"disc_loss\": disc_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Lf8y4gZFPeUp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import welch\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from scipy.stats import lognorm\n",
        "\n",
        "def plot_psd(series, fs=1, label='PSD'):\n",
        "    f, Pxx = welch(series, fs=fs, nperseg=256)\n",
        "    plt.semilogy(f, Pxx, label=label)\n",
        "    plt.xlabel(\"Frequency (Hz)\")\n",
        "    plt.ylabel(\"Power\")\n",
        "    plt.title(\"Power Spectral Density\")\n",
        "    plt.legend()\n",
        "\n",
        "def plot_acf(series, lags=100, label='ACF'):\n",
        "    autocorr = acf(series, nlags=lags, fft=True)\n",
        "    plt.plot(autocorr, label=label)\n",
        "    plt.xlabel(\"Lag\")\n",
        "    plt.ylabel(\"Autocorrelation\")\n",
        "    plt.title(\"ACF\")\n",
        "    plt.legend()\n",
        "\n",
        "def plot_flux_histogram(series, label='Generated'):\n",
        "    shape, loc, scale = lognorm.fit(series - np.min(series) + 1e-6)\n",
        "    x = np.linspace(np.min(series), np.max(series), 100)\n",
        "    pdf = lognorm.pdf(x, shape, loc, scale)\n",
        "\n",
        "    plt.hist(series, bins=40, density=True, alpha=0.6, label=f\"{label} Flux\")\n",
        "    plt.plot(x, pdf, '--', label=f\"LogNorm Fit ({label})\")\n",
        "    plt.xlabel(\"Flux\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.title(\"Flux Histogram with Log-normal Fit\")\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l2nViXahPeUp"
      },
      "outputs": [],
      "source": [
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "class GANMonitor(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, generator, val_dataset, latent_dim, num_samples=3, label=[0, 1], save_dir=\"gan_outputs\"):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "        self.val_dataset = val_dataset\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_samples = num_samples\n",
        "        self.label = tf.convert_to_tensor([label] * num_samples, dtype=tf.float32)\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        noise = tf.random.normal([self.num_samples, self.latent_dim])\n",
        "        generated = self.generator([noise, self.label], training=False).numpy().squeeze()\n",
        "        real_samples = next(iter(self.val_dataset))[0].numpy().squeeze()[:self.num_samples]\n",
        "\n",
        "        pdf_path = os.path.join(self.save_dir, f\"epoch_{epoch+1}.pdf\")\n",
        "        with PdfPages(pdf_path) as pdf:\n",
        "            for i in range(self.num_samples):\n",
        "                fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "                plt.sca(axes[0])\n",
        "                plot_psd(generated[i], label='Generated')\n",
        "                plot_psd(real_samples[i], label='Real')\n",
        "\n",
        "                plt.sca(axes[1])\n",
        "                plot_acf(generated[i], label='Generated')\n",
        "                plot_acf(real_samples[i], label='Real')\n",
        "\n",
        "                plt.sca(axes[2])\n",
        "                plot_flux_histogram(generated[i], label='Generated')\n",
        "                plot_flux_histogram(real_samples[i], label='Real')\n",
        "\n",
        "                plt.suptitle(f\"Sample {i + 1} – Epoch {epoch + 1}\")\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # ✅ Save this figure as one page in the PDF\n",
        "                pdf.savefig(fig)\n",
        "                plt.close(fig)\n",
        "\n",
        "        print(f\"📄 Saved PDF for epoch {epoch + 1} at: {pdf_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s-5LoZAQchyl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(\"saved_models/conditional_gan_training_log.csv\", append=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-MzcFDm7PeUq",
        "outputId": "a7c96c22-9164-4357-ecda-ff23d39718af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - disc_loss: 1.3843 - gen_loss: 0.6989📄 Saved PDF for epoch 1 at: gan_outputs/epoch_1.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 208ms/step - disc_loss: 1.3835 - gen_loss: 0.7000\n",
            "Epoch 2/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 1.3747 - gen_loss: 0.6981📄 Saved PDF for epoch 2 at: gan_outputs/epoch_2.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 198ms/step - disc_loss: 1.3739 - gen_loss: 0.6986\n",
            "Epoch 3/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.3843 - gen_loss: 0.6814📄 Saved PDF for epoch 3 at: gan_outputs/epoch_3.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 193ms/step - disc_loss: 1.3835 - gen_loss: 0.6825\n",
            "Epoch 4/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 1.3677 - gen_loss: 0.7196📄 Saved PDF for epoch 4 at: gan_outputs/epoch_4.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.3673 - gen_loss: 0.7196\n",
            "Epoch 5/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.3446 - gen_loss: 0.7322📄 Saved PDF for epoch 5 at: gan_outputs/epoch_5.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 199ms/step - disc_loss: 1.3441 - gen_loss: 0.7325\n",
            "Epoch 6/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.2535 - gen_loss: 0.7768📄 Saved PDF for epoch 6 at: gan_outputs/epoch_6.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.2534 - gen_loss: 0.7784\n",
            "Epoch 7/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.2933 - gen_loss: 2.8330📄 Saved PDF for epoch 7 at: gan_outputs/epoch_7.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 0.2914 - gen_loss: 2.8362\n",
            "Epoch 8/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 0.0307 - gen_loss: 3.9798📄 Saved PDF for epoch 8 at: gan_outputs/epoch_8.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 0.0305 - gen_loss: 3.9833\n",
            "Epoch 9/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.0245 - gen_loss: 4.2087📄 Saved PDF for epoch 9 at: gan_outputs/epoch_9.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 199ms/step - disc_loss: 0.0244 - gen_loss: 4.2107\n",
            "Epoch 10/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.0096 - gen_loss: 5.1107📄 Saved PDF for epoch 10 at: gan_outputs/epoch_10.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 0.0096 - gen_loss: 5.1134\n",
            "Epoch 11/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.0035 - gen_loss: 5.9034📄 Saved PDF for epoch 11 at: gan_outputs/epoch_11.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - disc_loss: 0.0035 - gen_loss: 5.9068\n",
            "Epoch 12/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.0019 - gen_loss: 6.5839📄 Saved PDF for epoch 12 at: gan_outputs/epoch_12.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 0.0019 - gen_loss: 6.5856\n",
            "Epoch 13/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - disc_loss: 0.0014 - gen_loss: 6.9569📄 Saved PDF for epoch 13 at: gan_outputs/epoch_13.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 200ms/step - disc_loss: 0.0014 - gen_loss: 6.9578\n",
            "Epoch 14/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 0.0012 - gen_loss: 7.1154📄 Saved PDF for epoch 14 at: gan_outputs/epoch_14.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 0.0012 - gen_loss: 7.1155\n",
            "Epoch 15/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 0.0010 - gen_loss: 7.2327📄 Saved PDF for epoch 15 at: gan_outputs/epoch_15.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 0.0010 - gen_loss: 7.2334\n",
            "Epoch 16/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 8.7534e-04 - gen_loss: 7.4192📄 Saved PDF for epoch 16 at: gan_outputs/epoch_16.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 8.7467e-04 - gen_loss: 7.4201\n",
            "Epoch 17/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 7.1613e-04 - gen_loss: 7.6501📄 Saved PDF for epoch 17 at: gan_outputs/epoch_17.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 7.1560e-04 - gen_loss: 7.6510\n",
            "Epoch 18/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - disc_loss: 6.0287e-04 - gen_loss: 7.8443📄 Saved PDF for epoch 18 at: gan_outputs/epoch_18.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - disc_loss: 6.0252e-04 - gen_loss: 7.8451\n",
            "Epoch 19/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 5.2477e-04 - gen_loss: 7.9925📄 Saved PDF for epoch 19 at: gan_outputs/epoch_19.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 200ms/step - disc_loss: 5.2452e-04 - gen_loss: 7.9929\n",
            "Epoch 20/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 4.6772e-04 - gen_loss: 8.1069📄 Saved PDF for epoch 20 at: gan_outputs/epoch_20.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 193ms/step - disc_loss: 4.6753e-04 - gen_loss: 8.1072\n",
            "Epoch 21/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - disc_loss: 4.2105e-04 - gen_loss: 8.2078📄 Saved PDF for epoch 21 at: gan_outputs/epoch_21.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 4.2089e-04 - gen_loss: 8.2082\n",
            "Epoch 22/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 3.8393e-04 - gen_loss: 8.2904📄 Saved PDF for epoch 22 at: gan_outputs/epoch_22.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 3.8385e-04 - gen_loss: 8.2905\n",
            "Epoch 23/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - disc_loss: 3.6398e-04 - gen_loss: 8.3170📄 Saved PDF for epoch 23 at: gan_outputs/epoch_23.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 274ms/step - disc_loss: 3.6388e-04 - gen_loss: 8.3172\n",
            "Epoch 24/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - disc_loss: 3.5392e-04 - gen_loss: 8.3098📄 Saved PDF for epoch 24 at: gan_outputs/epoch_24.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - disc_loss: 3.5388e-04 - gen_loss: 8.3098\n",
            "Epoch 25/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 3.1462e-04 - gen_loss: 8.4343📄 Saved PDF for epoch 25 at: gan_outputs/epoch_25.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 3.1439e-04 - gen_loss: 8.4352\n",
            "Epoch 26/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 2.6614e-04 - gen_loss: 8.6302📄 Saved PDF for epoch 26 at: gan_outputs/epoch_26.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 203ms/step - disc_loss: 2.6601e-04 - gen_loss: 8.6307\n",
            "Epoch 27/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 2.4041e-04 - gen_loss: 8.7337📄 Saved PDF for epoch 27 at: gan_outputs/epoch_27.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 193ms/step - disc_loss: 2.4036e-04 - gen_loss: 8.7338\n",
            "Epoch 28/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 2.1562e-04 - gen_loss: 8.8506📄 Saved PDF for epoch 28 at: gan_outputs/epoch_28.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 2.1549e-04 - gen_loss: 8.8513\n",
            "Epoch 29/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 2.0967e-04 - gen_loss: 8.8609📄 Saved PDF for epoch 29 at: gan_outputs/epoch_29.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 2.1007e-04 - gen_loss: 8.8583\n",
            "Epoch 30/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 2.2668e-04 - gen_loss: 8.7042📄 Saved PDF for epoch 30 at: gan_outputs/epoch_30.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 2.2646e-04 - gen_loss: 8.7055\n",
            "Epoch 31/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.7867e-04 - gen_loss: 8.9927📄 Saved PDF for epoch 31 at: gan_outputs/epoch_31.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.7854e-04 - gen_loss: 8.9936\n",
            "Epoch 32/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.5015e-04 - gen_loss: 9.2026📄 Saved PDF for epoch 32 at: gan_outputs/epoch_32.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.5007e-04 - gen_loss: 9.2032\n",
            "Epoch 33/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.3027e-04 - gen_loss: 9.3715📄 Saved PDF for epoch 33 at: gan_outputs/epoch_33.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.3021e-04 - gen_loss: 9.3721\n",
            "Epoch 34/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.1517e-04 - gen_loss: 9.5156📄 Saved PDF for epoch 34 at: gan_outputs/epoch_34.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 204ms/step - disc_loss: 1.1512e-04 - gen_loss: 9.5161\n",
            "Epoch 35/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.0315e-04 - gen_loss: 9.6418📄 Saved PDF for epoch 35 at: gan_outputs/epoch_35.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 192ms/step - disc_loss: 1.0311e-04 - gen_loss: 9.6423\n",
            "Epoch 36/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 9.3330e-05 - gen_loss: 9.7538📄 Saved PDF for epoch 36 at: gan_outputs/epoch_36.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 9.3295e-05 - gen_loss: 9.7542\n",
            "Epoch 37/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 8.5211e-05 - gen_loss: 9.8524📄 Saved PDF for epoch 37 at: gan_outputs/epoch_37.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 8.5183e-05 - gen_loss: 9.8528\n",
            "Epoch 38/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 7.8530e-05 - gen_loss: 9.9369📄 Saved PDF for epoch 38 at: gan_outputs/epoch_38.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 192ms/step - disc_loss: 7.8507e-05 - gen_loss: 9.9372\n",
            "Epoch 39/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - disc_loss: 7.3235e-05 - gen_loss: 10.0029📄 Saved PDF for epoch 39 at: gan_outputs/epoch_39.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 215ms/step - disc_loss: 7.3217e-05 - gen_loss: 10.0030\n",
            "Epoch 40/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 6.9509e-05 - gen_loss: 10.0416📄 Saved PDF for epoch 40 at: gan_outputs/epoch_40.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 193ms/step - disc_loss: 6.9502e-05 - gen_loss: 10.0416\n",
            "Epoch 41/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - disc_loss: 6.7493e-05 - gen_loss: 10.0464📄 Saved PDF for epoch 41 at: gan_outputs/epoch_41.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 198ms/step - disc_loss: 6.7486e-05 - gen_loss: 10.0464\n",
            "Epoch 42/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 6.5674e-05 - gen_loss: 10.0506📄 Saved PDF for epoch 42 at: gan_outputs/epoch_42.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 6.5660e-05 - gen_loss: 10.0507\n",
            "Epoch 43/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 6.0256e-05 - gen_loss: 10.1426📄 Saved PDF for epoch 43 at: gan_outputs/epoch_43.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 206ms/step - disc_loss: 6.0227e-05 - gen_loss: 10.1432\n",
            "Epoch 44/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - disc_loss: 5.3387e-05 - gen_loss: 10.2857📄 Saved PDF for epoch 44 at: gan_outputs/epoch_44.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 197ms/step - disc_loss: 5.3361e-05 - gen_loss: 10.2862\n",
            "Epoch 45/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 4.7910e-05 - gen_loss: 10.4106📄 Saved PDF for epoch 45 at: gan_outputs/epoch_45.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 4.7897e-05 - gen_loss: 10.4108\n",
            "Epoch 46/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 5.6871e-05 - gen_loss: 10.1363📄 Saved PDF for epoch 46 at: gan_outputs/epoch_46.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 5.6832e-05 - gen_loss: 10.1371\n",
            "Epoch 47/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 4.6443e-05 - gen_loss: 10.3760📄 Saved PDF for epoch 47 at: gan_outputs/epoch_47.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 194ms/step - disc_loss: 4.6410e-05 - gen_loss: 10.3770\n",
            "Epoch 48/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 3.9387e-05 - gen_loss: 10.5829📄 Saved PDF for epoch 48 at: gan_outputs/epoch_48.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 3.9365e-05 - gen_loss: 10.5836\n",
            "Epoch 49/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 3.4661e-05 - gen_loss: 10.7408📄 Saved PDF for epoch 49 at: gan_outputs/epoch_49.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - disc_loss: 3.4647e-05 - gen_loss: 10.7413\n",
            "Epoch 50/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 3.1045e-05 - gen_loss: 10.8745📄 Saved PDF for epoch 50 at: gan_outputs/epoch_50.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - disc_loss: 3.1033e-05 - gen_loss: 10.8750\n",
            "Epoch 51/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 2.8244e-05 - gen_loss: 10.9848📄 Saved PDF for epoch 51 at: gan_outputs/epoch_51.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 197ms/step - disc_loss: 2.8234e-05 - gen_loss: 10.9852\n",
            "Epoch 52/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 2.5919e-05 - gen_loss: 11.0820📄 Saved PDF for epoch 52 at: gan_outputs/epoch_52.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 193ms/step - disc_loss: 2.5910e-05 - gen_loss: 11.0824\n",
            "Epoch 53/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 2.3916e-05 - gen_loss: 11.1706📄 Saved PDF for epoch 53 at: gan_outputs/epoch_53.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 2.3908e-05 - gen_loss: 11.1709\n",
            "Epoch 54/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 2.2147e-05 - gen_loss: 11.2536📄 Saved PDF for epoch 54 at: gan_outputs/epoch_54.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 2.2140e-05 - gen_loss: 11.2540\n",
            "Epoch 55/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - disc_loss: 2.0557e-05 - gen_loss: 11.3330📄 Saved PDF for epoch 55 at: gan_outputs/epoch_55.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 210ms/step - disc_loss: 2.0551e-05 - gen_loss: 11.3332\n",
            "Epoch 56/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - disc_loss: 1.9087e-05 - gen_loss: 11.4119📄 Saved PDF for epoch 56 at: gan_outputs/epoch_56.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 1.9082e-05 - gen_loss: 11.4123\n",
            "Epoch 57/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.7707e-05 - gen_loss: 11.4925📄 Saved PDF for epoch 57 at: gan_outputs/epoch_57.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.7701e-05 - gen_loss: 11.4928\n",
            "Epoch 58/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 1.6405e-05 - gen_loss: 11.5754📄 Saved PDF for epoch 58 at: gan_outputs/epoch_58.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 192ms/step - disc_loss: 1.6400e-05 - gen_loss: 11.5757\n",
            "Epoch 59/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - disc_loss: 1.5184e-05 - gen_loss: 11.6604📄 Saved PDF for epoch 59 at: gan_outputs/epoch_59.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 196ms/step - disc_loss: 1.5178e-05 - gen_loss: 11.6607\n",
            "Epoch 60/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.4046e-05 - gen_loss: 11.7465📄 Saved PDF for epoch 60 at: gan_outputs/epoch_60.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - disc_loss: 1.4042e-05 - gen_loss: 11.7468\n",
            "Epoch 61/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.2995e-05 - gen_loss: 11.8327📄 Saved PDF for epoch 61 at: gan_outputs/epoch_61.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.2991e-05 - gen_loss: 11.8331\n",
            "Epoch 62/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.2028e-05 - gen_loss: 11.9184📄 Saved PDF for epoch 62 at: gan_outputs/epoch_62.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 1.2025e-05 - gen_loss: 11.9189\n",
            "Epoch 63/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.1141e-05 - gen_loss: 12.0033📄 Saved PDF for epoch 63 at: gan_outputs/epoch_63.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.1137e-05 - gen_loss: 12.0037\n",
            "Epoch 64/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.0327e-05 - gen_loss: 12.0870📄 Saved PDF for epoch 64 at: gan_outputs/epoch_64.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.0324e-05 - gen_loss: 12.0873\n",
            "Epoch 65/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 9.5792e-06 - gen_loss: 12.1697📄 Saved PDF for epoch 65 at: gan_outputs/epoch_65.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 9.5765e-06 - gen_loss: 12.1700\n",
            "Epoch 66/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 8.8897e-06 - gen_loss: 12.2517📄 Saved PDF for epoch 66 at: gan_outputs/epoch_66.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - disc_loss: 8.8871e-06 - gen_loss: 12.2521\n",
            "Epoch 67/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 8.2542e-06 - gen_loss: 12.3330📄 Saved PDF for epoch 67 at: gan_outputs/epoch_67.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 8.2520e-06 - gen_loss: 12.3333\n",
            "Epoch 68/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 7.6693e-06 - gen_loss: 12.4131📄 Saved PDF for epoch 68 at: gan_outputs/epoch_68.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 192ms/step - disc_loss: 7.6673e-06 - gen_loss: 12.4134\n",
            "Epoch 69/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 7.1293e-06 - gen_loss: 12.4925📄 Saved PDF for epoch 69 at: gan_outputs/epoch_69.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 211ms/step - disc_loss: 7.1274e-06 - gen_loss: 12.4928\n",
            "Epoch 70/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - disc_loss: 6.6304e-06 - gen_loss: 12.5712📄 Saved PDF for epoch 70 at: gan_outputs/epoch_70.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 192ms/step - disc_loss: 6.6282e-06 - gen_loss: 12.5715\n",
            "Epoch 71/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 6.1693e-06 - gen_loss: 12.6491📄 Saved PDF for epoch 71 at: gan_outputs/epoch_71.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 6.1677e-06 - gen_loss: 12.6494\n",
            "Epoch 72/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 5.7432e-06 - gen_loss: 12.7261📄 Saved PDF for epoch 72 at: gan_outputs/epoch_72.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 5.7415e-06 - gen_loss: 12.7265\n",
            "Epoch 73/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 5.3482e-06 - gen_loss: 12.8025📄 Saved PDF for epoch 73 at: gan_outputs/epoch_73.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 5.3468e-06 - gen_loss: 12.8028\n",
            "Epoch 74/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 4.9821e-06 - gen_loss: 12.8783📄 Saved PDF for epoch 74 at: gan_outputs/epoch_74.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 4.9808e-06 - gen_loss: 12.8786\n",
            "Epoch 75/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 4.6428e-06 - gen_loss: 12.9535📄 Saved PDF for epoch 75 at: gan_outputs/epoch_75.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 196ms/step - disc_loss: 4.6415e-06 - gen_loss: 12.9538\n",
            "Epoch 76/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 4.3281e-06 - gen_loss: 13.0279📄 Saved PDF for epoch 76 at: gan_outputs/epoch_76.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 197ms/step - disc_loss: 4.3269e-06 - gen_loss: 13.0283\n",
            "Epoch 77/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 4.0360e-06 - gen_loss: 13.1018📄 Saved PDF for epoch 77 at: gan_outputs/epoch_77.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 194ms/step - disc_loss: 4.0348e-06 - gen_loss: 13.1021\n",
            "Epoch 78/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 3.7649e-06 - gen_loss: 13.1750📄 Saved PDF for epoch 78 at: gan_outputs/epoch_78.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 199ms/step - disc_loss: 3.7639e-06 - gen_loss: 13.1754\n",
            "Epoch 79/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - disc_loss: 3.5130e-06 - gen_loss: 13.2477📄 Saved PDF for epoch 79 at: gan_outputs/epoch_79.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 195ms/step - disc_loss: 3.5120e-06 - gen_loss: 13.2479\n",
            "Epoch 80/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - disc_loss: 3.2790e-06 - gen_loss: 13.3197📄 Saved PDF for epoch 80 at: gan_outputs/epoch_80.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 3.2781e-06 - gen_loss: 13.3200\n",
            "Epoch 81/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - disc_loss: 3.0614e-06 - gen_loss: 13.3912📄 Saved PDF for epoch 81 at: gan_outputs/epoch_81.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - disc_loss: 3.0606e-06 - gen_loss: 13.3915\n",
            "Epoch 82/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - disc_loss: 2.8839e-06 - gen_loss: 13.4443📄 Saved PDF for epoch 82 at: gan_outputs/epoch_82.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - disc_loss: 2.8831e-06 - gen_loss: 13.4446\n",
            "Epoch 83/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - disc_loss: 2.6966e-06 - gen_loss: 13.5121📄 Saved PDF for epoch 83 at: gan_outputs/epoch_83.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 2.6958e-06 - gen_loss: 13.5123\n",
            "Epoch 84/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 2.5117e-06 - gen_loss: 13.5873📄 Saved PDF for epoch 84 at: gan_outputs/epoch_84.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 2.5110e-06 - gen_loss: 13.5876\n",
            "Epoch 85/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - disc_loss: 2.3413e-06 - gen_loss: 13.6612📄 Saved PDF for epoch 85 at: gan_outputs/epoch_85.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 196ms/step - disc_loss: 2.3407e-06 - gen_loss: 13.6615\n",
            "Epoch 86/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - disc_loss: 2.1838e-06 - gen_loss: 13.7339📄 Saved PDF for epoch 86 at: gan_outputs/epoch_86.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 2.1833e-06 - gen_loss: 13.7342\n",
            "Epoch 87/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 2.0380e-06 - gen_loss: 13.8056📄 Saved PDF for epoch 87 at: gan_outputs/epoch_87.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 216ms/step - disc_loss: 2.0376e-06 - gen_loss: 13.8059\n",
            "Epoch 88/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - disc_loss: 1.9028e-06 - gen_loss: 13.8764📄 Saved PDF for epoch 88 at: gan_outputs/epoch_88.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 197ms/step - disc_loss: 1.9023e-06 - gen_loss: 13.8767\n",
            "Epoch 89/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.7772e-06 - gen_loss: 13.9466📄 Saved PDF for epoch 89 at: gan_outputs/epoch_89.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.7767e-06 - gen_loss: 13.9468\n",
            "Epoch 90/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.6604e-06 - gen_loss: 14.0161📄 Saved PDF for epoch 90 at: gan_outputs/epoch_90.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.6600e-06 - gen_loss: 14.0164\n",
            "Epoch 91/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.5517e-06 - gen_loss: 14.0851📄 Saved PDF for epoch 91 at: gan_outputs/epoch_91.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 1.5513e-06 - gen_loss: 14.0854\n",
            "Epoch 92/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.4504e-06 - gen_loss: 14.1538📄 Saved PDF for epoch 92 at: gan_outputs/epoch_92.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - disc_loss: 1.4500e-06 - gen_loss: 14.1540\n",
            "Epoch 93/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.3559e-06 - gen_loss: 14.2221📄 Saved PDF for epoch 93 at: gan_outputs/epoch_93.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 193ms/step - disc_loss: 1.3556e-06 - gen_loss: 14.2223\n",
            "Epoch 94/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.2678e-06 - gen_loss: 14.2901📄 Saved PDF for epoch 94 at: gan_outputs/epoch_94.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.2675e-06 - gen_loss: 14.2903\n",
            "Epoch 95/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 1.1855e-06 - gen_loss: 14.3578📄 Saved PDF for epoch 95 at: gan_outputs/epoch_95.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 194ms/step - disc_loss: 1.1852e-06 - gen_loss: 14.3581\n",
            "Epoch 96/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.1088e-06 - gen_loss: 14.4254📄 Saved PDF for epoch 96 at: gan_outputs/epoch_96.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 195ms/step - disc_loss: 1.1084e-06 - gen_loss: 14.4256\n",
            "Epoch 97/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 1.0370e-06 - gen_loss: 14.4927📄 Saved PDF for epoch 97 at: gan_outputs/epoch_97.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 1.0368e-06 - gen_loss: 14.4930\n",
            "Epoch 98/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 9.7000e-07 - gen_loss: 14.5600📄 Saved PDF for epoch 98 at: gan_outputs/epoch_98.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 9.6969e-07 - gen_loss: 14.5602\n",
            "Epoch 99/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - disc_loss: 9.0751e-07 - gen_loss: 14.6269📄 Saved PDF for epoch 99 at: gan_outputs/epoch_99.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 9.0726e-07 - gen_loss: 14.6272\n",
            "Epoch 100/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - disc_loss: 8.4893e-07 - gen_loss: 14.6939📄 Saved PDF for epoch 100 at: gan_outputs/epoch_100.pdf\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - disc_loss: 8.4871e-07 - gen_loss: 14.6942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cf64b38250>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load data\n",
        "train_ds, val_ds = load_conditional_dataset(\n",
        "    \"qpo_experiments/dataset_random_amp/data.npz\", batch_size=64)\n",
        "\n",
        "# Build models\n",
        "latent_dim = 100\n",
        "generator = build_conditional_generator(latent_dim)\n",
        "discriminator = build_conditional_discriminator()\n",
        "\n",
        "gan = ConditionalTimeSeriesGAN(generator, discriminator, latent_dim)\n",
        "gan.compile()\n",
        "\n",
        "\n",
        "monitor = GANMonitor(generator, val_dataset=val_ds,\n",
        "                     latent_dim=latent_dim, label=[0, 1])  # QPO only\n",
        "gan.fit(train_ds, epochs=100, callbacks=[monitor, csv_logger])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBweOSj-dttz",
        "outputId": "13194fc7-afb7-4610-cba7-36d6f2d04444"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZzyIs7dnhB",
        "outputId": "a8c63e5f-8d3d-483a-c9f1-ef69e986491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Save generator and discriminator after training\n",
        "# os.makedirs(\"saved_models\", exist_ok=True)\n",
        "generator.save(\"saved_models/qpo_gan_generator.h5\")\n",
        "discriminator.save(\"saved_models/qpo_gan_discriminator.h5\")\n",
        "# shutil.copyfile('./conditional_gan_training_log.csv', 'drive/MyDrive/saved_models/gan_training_log.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j8cL2_-vdnhB"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# # Load generator and discriminator\n",
        "# generator = load_model(\"saved_models/generator_bigru.h5\", compile=False)\n",
        "# discriminator = load_model(\"saved_models/discriminator_bigru.h5\", compile=False)\n",
        "\n",
        "# generator.summary()  # Optional check"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/saved_models/gan_outputs.zip /content/gan_outputs/\n",
        "!zip -r /content/drive/MyDrive/saved_models/saved_models.zip /content/saved_models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VHdwOUBfeCl",
        "outputId": "05395fda-13a4-4ebe-9380-9ac41b8d5cef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/gan_outputs/ (stored 0%)\n",
            "  adding: content/gan_outputs/epoch_54.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_21.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_15.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_32.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_56.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_25.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_67.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_97.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_46.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_95.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_96.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_34.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_59.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_75.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_62.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_2.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_94.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_81.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_71.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_42.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_47.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_49.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_39.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_84.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_13.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_14.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_37.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_29.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_52.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_43.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_66.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_69.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_40.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_57.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_45.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_26.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_27.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_24.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_28.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_82.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_3.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_4.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_78.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_48.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_5.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_35.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_11.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_87.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_53.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_1.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_31.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_68.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_89.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_16.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_8.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_72.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_79.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_41.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_19.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_44.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_61.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_77.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_92.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_98.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_6.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_17.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_36.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_60.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_20.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_58.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_38.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_80.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_64.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_55.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_83.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_30.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_12.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_91.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_85.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_50.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_10.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_99.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_65.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_70.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_63.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_74.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_100.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_90.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_86.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_73.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_23.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_18.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_88.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_7.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_33.pdf (deflated 12%)\n",
            "  adding: content/gan_outputs/epoch_22.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_93.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_51.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_76.pdf (deflated 13%)\n",
            "  adding: content/gan_outputs/epoch_9.pdf (deflated 12%)\n",
            "  adding: content/saved_models/ (stored 0%)\n",
            "  adding: content/saved_models/conditional_gan_training_log.csv (deflated 56%)\n",
            "  adding: content/saved_models/qpo_gan_discriminator.h5 (deflated 27%)\n",
            "  adding: content/saved_models/qpo_gan_generator.h5 (deflated 8%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}