Certainly! Here's the same explanation formatted as **concise technical documentation notes** ‚Äî ideal for use in a research notebook, report, or as inline commentary.

---

## üß† **SBI Inference Method Notes (SNPE-based)**

### Overview:
This project uses **Simulation-Based Inference (SBI)** with the `sbi` Python library.  
Specifically, we implement:

> **Sequential Neural Posterior Estimation (SNPE)**

---

### ‚úÖ Method Summary:

| Component                     | Description |
|------------------------------|-------------|
| **Inference Type**           | Bayesian |
| **Approach**                 | Likelihood-free posterior estimation |
| **Algorithm Used**           | SNPE (Sequential Neural Posterior Estimation) |
| **Posterior Representation** | Neural density estimator (e.g., MAF, MDN, NSF) |
| **Sampling Strategy**        | Direct Monte Carlo sampling from learned posterior |
| **Simulator**                | GAN-generated light curves (QPO conditioned) |
| **Observation**              | PSD (Power Spectral Density) of input light curve |

---

### üß™ Sampling Details:

- Posterior is learned from `(Œ∏, x)` pairs, where:
  - `Œ∏` = `[fc, amp]` (latent parameters)
  - `x` = PSD (from GAN or real data)
- After training, the posterior is queried like:

```python
posterior.sample((500,), x=x_obs)
```

- This performs **direct Monte Carlo sampling** from the neural posterior:
  - Not MCMC (e.g., no chains, burn-in, etc.)
  - Sampling is fast, independent, and scalable

---

### ‚ùå Not Using:

- Markov Chain Monte Carlo (MCMC)
- Approximate Bayesian Computation (ABC)
- Traditional likelihood-based methods

---

### ‚úÖ Advantages of SNPE:

- Efficient inference on **high-dimensional simulators**
- Learns a flexible **parametric posterior** over `Œ∏`
- Does not require likelihood computation
- Supports sequential refinement of the posterior

---

### üß† Behind the Scenes (by default):

- Learns `p(Œ∏ | x)` using:
  - MAF (Masked Autoregressive Flow)
  - or Mixture Density Network (MDN), depending on config
- Posterior returned is a PyTorch object that supports:
  - `.sample()`
  - `.log_prob()`
  - `.condition_on_observation(x)`

---